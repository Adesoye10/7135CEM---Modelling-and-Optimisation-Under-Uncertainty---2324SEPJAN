{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXdLkTzwUrE-"
      },
      "outputs": [],
      "source": [
        "# Library Imports and Setup\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import matplotlib.ticker as ticker\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import math\n",
        "from scipy.stats import pearsonr, spearmanr, chi2_contingency, ttest_ind, mannwhitneyu, norm, normaltest, shapiro, anderson\n",
        "import operator\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
        "import time\n",
        "st = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loading and Initial Exploration\n",
        "drugdata = pd.read_csv(\"drug_consumption.csv\")\n",
        "drugdata.head()\n",
        "drugdata.columns = ['ID', 'Age', 'Gender', 'Education', 'Country', 'Ethnicity', 'Neuroticism', 'Extraversion', 'Openness to experience', 'Agreeableness', 'Conscientiousness', 'Impulsiveness', 'Sensation seeking', 'Alcohol consumption', 'Amphetamines consumption', 'Amyl nitrite consumption', 'Benzodiazepine consumption', 'Caffeine consumption', 'Cannabis consumption', 'Chocolate consumption', 'Cocaine consumption', 'Crack consumption', 'Ecstasy consumption', 'Heroin consumption', 'Ketamine consumption', 'Legal highs consumption', 'Lysergic acid diethylamide consumption', 'Methadone consumption', 'Magic mushrooms consumption', 'Nicotine consumption', 'Fictitious drug Semeron consumption', 'VSA']\n",
        "demographic_columns = [\n",
        "    'Age',\n",
        "    'Gender',\n",
        "    'Education',\n",
        "    'Country',\n",
        "    'Ethnicity',\n",
        "]\n",
        "\n",
        "personality_columns = [\n",
        "    'Neuroticism',\n",
        "    'Extraversion',\n",
        "    'Openness to experience',\n",
        "    'Agreeableness',\n",
        "    'Conscientiousness',\n",
        "    'Impulsiveness',\n",
        "    'Sensation seeking'\n",
        "]\n",
        "\n",
        "feature_columns = demographic_columns + personality_columns\n",
        "\n",
        "drugs_columns = [\n",
        "    'Alcohol consumption',\n",
        "    'Amphetamines consumption',\n",
        "    'Amyl nitrite consumption',\n",
        "    'Benzodiazepine consumption',\n",
        "    'Caffeine consumption',\n",
        "    'Cannabis consumption',\n",
        "    'Chocolate consumption',\n",
        "    'Cocaine consumption',\n",
        "    'Crack consumption',\n",
        "    'Ecstasy consumption',\n",
        "    'Heroin consumption',\n",
        "    'Ketamine consumption',\n",
        "    'Legal highs consumption',\n",
        "    'Lysergic acid diethylamide consumption',\n",
        "    'Methadone consumption',\n",
        "    'Magic mushrooms consumption',\n",
        "    'Nicotine consumption',\n",
        "    'VSA'\n",
        "]\n",
        "\n",
        "drugs_legal = ['Alcohol consumption', 'Caffeine consumption', 'Chocolate consumption', 'Nicotine consumption']\n",
        "\n",
        "drugs_illegal = [drug for drug in drugs_columns if drug not in drugs_legal]\n",
        "\n",
        "all_columns = feature_columns + drugs_columns"
      ],
      "metadata": {
        "id": "fLsNcvuPZACR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleaning and Preprocessing"
      ],
      "metadata": {
        "id": "iauCGzNoeQIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drugdata.dtypes\n",
        "drugdata.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGR3SBl8JDYv",
        "outputId": "81375b8f-bc4b-4d45-b5e5-9705595eee22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1884, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "drugdata.isna().sum().sum()\n",
        "# Fake results will be visualized and later removed\n",
        "filtered_data = drugdata.query(\"`Fictitious drug Semeron consumption` != 'CL0'\")\n",
        "filtered_data"
      ],
      "metadata": {
        "id": "DNsUwRP5WOtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We will drop overclaimers since, there answers might not truly be accurate\n",
        "drugdata = drugdata.drop(drugdata[drugdata['Fictitious drug Semeron consumption'] != 'CL0'].index)\n",
        "\n",
        "# We will also drop unnecesary columns\n",
        "drugdata = drugdata.drop(['ID','Fictitious drug Semeron consumption'], axis=1)\n",
        "drugdata = drugdata.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "ICg3TunsWkKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding Drug Consumption Data"
      ],
      "metadata": {
        "id": "UrHBOtr2ekJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drugdata.describe()\n",
        "def drug_encoder(x):\n",
        "    if x == 'CL0':\n",
        "        return 0\n",
        "    elif x == 'CL1':\n",
        "        return 1\n",
        "    elif x == 'CL2':\n",
        "        return 2\n",
        "    elif x == 'CL3':\n",
        "        return 3\n",
        "    elif x == 'CL4':\n",
        "        return 4\n",
        "    elif x == 'CL5':\n",
        "        return 5\n",
        "    elif x == 'CL6':\n",
        "        return 6\n",
        "    else:\n",
        "        return 7"
      ],
      "metadata": {
        "id": "-H6no_dIiDYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for column in drugs_columns:\n",
        "  drugdata[column] = drugdata[column].apply(drug_encoder)\n",
        "drugdata.head()"
      ],
      "metadata": {
        "id": "GPvX2tNfiLTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Visualization - Box Plot\n",
        "fig, ax = plt.subplots(figsize=(7,10))\n",
        "plt.ylabel(\"Features\")\n",
        "plt.title(\"Box plot of Pre-Processed Data Set\")\n",
        "ax = sns.boxplot(data = drugdata[feature_columns], orient=\"h\", palette=\"Set2\")\n",
        "sns.reset_orig()"
      ],
      "metadata": {
        "id": "o6n_45h5J7vB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Demographic Data Preparation\n",
        "demo_data = drugdata.copy()\n",
        "age = ['18-24' if a <= -0.9 else\n",
        "       '25-34' if a >= -0.5 and a < 0 else\n",
        "       '35-44' if a > 0 and a < 1 else\n",
        "       '45-54' if a > 1 and a < 1.5 else\n",
        "       '55-64' if a > 1.5 and a < 2 else\n",
        "       '65+'\n",
        "       for a in demo_data['Age']]\n",
        "\n",
        "gender = ['Female' if g > 0 else \"Male\" for g in demo_data['Gender']]\n",
        "\n",
        "education = ['Left school before 16 years' if e <-2 else\n",
        "             'Left school at 16 years' if e > -2 and e < -1.5 else\n",
        "             'Left school at 17 years' if e > -1.5 and e < -1.4 else\n",
        "             'Left school at 18 years' if e > -1.4 and e < -1 else\n",
        "             'Some college or university, no certificate or degree' if e > -1 and e < -0.5 else\n",
        "             'Professional certificate/ diploma' if e > -0.5 and e < 0 else\n",
        "             'University degree' if e > 0 and e < 0.5 else\n",
        "             'Masters degree' if e > 0.5 and e < 1.5 else\n",
        "             'Doctorate degree'\n",
        "             for e in demo_data['Education']]\n",
        "\n",
        "country = ['USA' if c < -0.5 else\n",
        "           'New Zealand' if c > -0.5 and c < -0.4 else\n",
        "           'Other' if c > -0.4 and c < -0.2 else\n",
        "           'Australia' if c > -0.2 and c < 0 else\n",
        "           'Ireland' if c > 0 and c < 0.23 else\n",
        "           'Canada' if c > 0.23 and c < 0.9 else\n",
        "           'UK'\n",
        "           for c in demo_data['Country']]\n",
        "\n",
        "ethnicity = ['Black' if e < -1 else\n",
        "             'Asian' if e > -1 and e < -0.4 else\n",
        "             'White' if e > -0.4 and e < -0.25 else\n",
        "             'Mixed-White/Black' if e >= -0.25 and e < 0.11 else\n",
        "             'Mixed-White/Asian' if e > 0.12 and e < 1 else\n",
        "             'Mixed-Black/Asian' if e > 1.9 else\n",
        "             'Other'\n",
        "             for e in demo_data['Ethnicity']]\n",
        "\n",
        "\n",
        "demo_data['Age'] = age\n",
        "demo_data['Gender'] = gender\n",
        "demo_data['Education'] = education\n",
        "demo_data['Country'] = country\n",
        "demo_data['Ethnicity'] = ethnicity"
      ],
      "metadata": {
        "id": "vtgZL3P_KG-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo_data[demographic_columns].head()"
      ],
      "metadata": {
        "id": "nbsB4i0UKdmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_density(dataset, col, ax, plot_gaussian = True, color=\"Blue\"):\n",
        "    '''\n",
        "    Extension of the seaborn histogram that plots, for a given column, an estimated normal distribution (if requested) on top of the fitted data distribution.\n",
        "    '''\n",
        "    ncount = len(dataset)\n",
        "\n",
        "    if plot_gaussian:\n",
        "        std = dataset[col].std()\n",
        "        mean = dataset[col].mean()\n",
        "\n",
        "    #plot histogram using seaborn\n",
        "    ax = sns.histplot(dataset[col], ax=ax, color=color, kde=True, stat=\"probability\", kde_kws={\"bw_adjust\":3})\n",
        "\n",
        "    if plot_gaussian:\n",
        "        # Limiting our gaussian to the limits from the above plot\n",
        "        xmin, xmax = ax.get_xlim()\n",
        "        xnorm = np.arange(xmin, xmax, 0.001)\n",
        "        ynorm = norm.pdf(xnorm, mean, std)\n",
        "        ax.plot(xnorm, ynorm, 'r', lw=2)\n",
        "        ax.legend([\"data distribution\", \"estimated normal distribution\"], loc=\"upper center\", bbox_to_anchor=(0.5, -0.05), fancybox=True, shadow=True, ncol=2)\n",
        "\n",
        "    ax.set_title(col)\n",
        "    ax.set_xlabel(\"\")"
      ],
      "metadata": {
        "id": "DXsUEhX7KfOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_pie(dataset, col, ax):\n",
        "    '''\n",
        "    Pandas' pie plot wrapper\n",
        "    '''\n",
        "    ax = dataset[col].value_counts().plot(kind='pie', ax=ax)\n",
        "    ax.set_title(col)\n",
        "    ax.set_ylabel(\"\")"
      ],
      "metadata": {
        "id": "T0Eo55jVKmkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_count(dataset, col, ax, order = None, show_percent=True, rotate_label = True, add_args={\"palette\": \"Set2\"}):\n",
        "    '''\n",
        "    Extending the seaorn countplot to get frequencies and counts in a pretty way.\n",
        "    '''\n",
        "\n",
        "    ncount = len(dataset)\n",
        "\n",
        "    if order is None:\n",
        "        order = np.sort(dataset[col].unique())\n",
        "\n",
        "    # plot seaborn countplot\n",
        "    ax = sns.countplot(data=dataset, x=col, ax=ax, order=order, **add_args)\n",
        "\n",
        "    # Get y limit (number of elements)\n",
        "    _ ,max_nb = ax.get_ylim()\n",
        "    # Transform this limit into a frequency in [0, 100]\n",
        "    freq_lim = (max_nb * 100/ ncount)\n",
        "\n",
        "    # Duplicate the ax\n",
        "    ax2 = ax.twinx()\n",
        "\n",
        "    #Move duplicate y axis ticks to the left\n",
        "    ax2.yaxis.tick_left()\n",
        "\n",
        "    #Move original y axis ticks to the right\n",
        "    ax.yaxis.tick_right()\n",
        "\n",
        "    # Swap the label positions to match the ticks\n",
        "    ax.yaxis.set_label_position('right')\n",
        "    ax2.yaxis.set_label_position('left')\n",
        "    ax2.set_ylabel('Frequency [%]')\n",
        "\n",
        "    # We want to write the frequency on top of each bar\n",
        "    if show_percent:\n",
        "        # for every bar\n",
        "        for p in ax.patches:\n",
        "            x=p.get_bbox().get_points()[:,0]\n",
        "            y=p.get_bbox().get_points()[1,1]\n",
        "            if not math.isnan(x.mean()) and not math.isnan(y):\n",
        "                # Write frequency at an x and y coordinate\n",
        "                ax.text(x.mean(), y, '{:.1f}%'.format(100.*y/ncount),\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "    # Set y axis limit for counts and frequencies\n",
        "    ax2.set_ylim(0,freq_lim)\n",
        "    ax.set_ylim(0,max_nb)\n",
        "\n",
        "    # set ticks for count\n",
        "    ax.yaxis.set_major_locator(ticker.LinearLocator(11))\n",
        "    ax.yaxis.set_tick_params(which=\"major\")\n",
        "\n",
        "    # set ticks for frequencies\n",
        "    ax2.yaxis.set_major_locator(ticker.MultipleLocator(freq_lim/10))\n",
        "    ax2.yaxis.set_tick_params(which=\"major\")\n",
        "\n",
        "    # remove grid for ax 2 (keep only ax)\n",
        "    ax2.grid(False)\n",
        "    ax.grid(False)\n",
        "    ax.set_xlabel(\"\")\n",
        "    if rotate_label:\n",
        "        # rotate tick labels on the x axis / / /\n",
        "        _ = ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
        "    ax.set_title(col)"
      ],
      "metadata": {
        "id": "XocoMqYZKsYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot(kind, dataset, columns=None, fig_title=\"Count/Frequency plots\", fontsizes = 20, **kwargs):\n",
        "    '''\n",
        "    Wrapper function that takes care of plot wise sizes and calling the wanted procedure\n",
        "    '''\n",
        "\n",
        "    # plot choices\n",
        "    kind_dict = {\n",
        "        'pie': plot_pie,\n",
        "        'count': plot_count,\n",
        "        'density': plot_density}\n",
        "\n",
        "    if kind not in kind_dict:\n",
        "        raise ValueError(f\"{kind} is not a valid kind, has to be one of {kind_dict.keys()}\")\n",
        "\n",
        "    if columns is None:\n",
        "        # us all dataset columns\n",
        "        columns = list(dataset.columns)\n",
        "\n",
        "    fig = None\n",
        "\n",
        "    # Setting font sizes\n",
        "    plt.rc('xtick', labelsize=fontsizes*1.5)\n",
        "    plt.rc('ytick', labelsize=fontsizes*1.5)\n",
        "    plt.rc('axes', labelsize=fontsizes*2)\n",
        "    plt.rc('legend', fontsize=fontsizes*1.5, title_fontsize=0)\n",
        "    plt.rc('axes', titlesize=2*fontsizes)\n",
        "    plt.rc('font', size=1.7*fontsizes)\n",
        "\n",
        "    # Scale of the figure in ax (to be used later)\n",
        "    figsize_scale = fontsizes\n",
        "\n",
        "    if not isinstance(columns, list):\n",
        "        # columns has to be a list\n",
        "        if isinstance(columns, str):\n",
        "            columns = [columns]\n",
        "        else:\n",
        "            columns = list(columns)\n",
        "\n",
        "    if len(columns) == 1: # Only variable to plot\n",
        "        ncols, nrows = 1, 1\n",
        "        figsize_scale *= 2 # double figsize\n",
        "    else:\n",
        "        ncols, nrows = 2, math.ceil(len(columns) / 2)\n",
        "\n",
        "    fig, axes = plt.subplots(figsize=(figsize_scale*ncols, figsize_scale*nrows), nrows=nrows, ncols=ncols)\n",
        "\n",
        "    if ncols == 1 and nrows == 1:\n",
        "        # We need a list of axes\n",
        "        axes = np.array([axes])\n",
        "\n",
        "    # Plot\n",
        "    do_plots(dataset, columns, axes, kind_dict[kind], **kwargs)\n",
        "\n",
        "    fig.suptitle(fig_title + \"\\n\\n\", fontsize=fontsizes*2.5)\n",
        "    plt.tight_layout()\n",
        "    #Reset plot setting to original\n",
        "    sns.reset_orig()\n",
        "\n",
        "def do_plots(dataset, columns, axes, plot_func, **kwargs):\n",
        "    '''\n",
        "    Calls the plotting function on every axis and removes unused axes.\n",
        "    '''\n",
        "    axes = axes.flat\n",
        "\n",
        "    #plot every variable\n",
        "    for index, col in enumerate(columns):\n",
        "        plot_func(dataset, col, axes[index], **kwargs)\n",
        "\n",
        "    # remove empty axes\n",
        "    for empty in range(len(columns), len(axes)):\n",
        "        axes[empty].axis(\"off\")"
      ],
      "metadata": {
        "id": "Eu4V5p60KwRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Visualization - Pie and Count Plots"
      ],
      "metadata": {
        "id": "hQlQAAjAx9kG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot(\"pie\", demo_data, demographic_columns, fig_title=\"Plot pies of demographic data\")"
      ],
      "metadata": {
        "id": "rqqv4I04K1XH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(\"count\", demo_data, demographic_columns, fig_title=\"Count / Frequency plots of demographic data\")"
      ],
      "metadata": {
        "id": "JEWvsN5BLVCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The function below creates a dataframe with count and frequencies for a given column.\n",
        "def value_counts_percentage(dataset, column):\n",
        "    ''' value.counts() method extended by displaying percentage '''\n",
        "\n",
        "    a = dataset[column].value_counts()\n",
        "    b = dataset[column].value_counts(normalize=True) * 100\n",
        "\n",
        "    return pd.concat([a,b.round(2)], axis=1, keys=['N', '%'])"
      ],
      "metadata": {
        "id": "ti1XBsEdLM5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statistical Analysis and Data Transformation"
      ],
      "metadata": {
        "id": "mmUAe9EiyEWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "value_counts_percentage(demo_data, 'Age')"
      ],
      "metadata": {
        "id": "GNXrXk3pL6hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value_counts_percentage(demo_data, 'Gender')"
      ],
      "metadata": {
        "id": "pb8abrSCL-7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value_counts_percentage(demo_data, 'Education')"
      ],
      "metadata": {
        "id": "Zvbp6jRqMEBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value_counts_percentage(demo_data, 'Country')"
      ],
      "metadata": {
        "id": "pEXLTKz9MM4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value_counts_percentage(demo_data, 'Ethnicity')"
      ],
      "metadata": {
        "id": "ehOwwKxUMRoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(\"count\", demo_data, 'Age', fig_title=\"Age-Gender count/frequency\", rotate_label=False, add_args={\"hue\":\"Gender\", \"palette\":'ch:.25'}, fontsizes=4.5);"
      ],
      "metadata": {
        "id": "zUL5_mb_MVmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(\"count\", demo_data, 'Country', fig_title=\"Age-Gender count/frequency\", rotate_label=False, add_args={\"hue\":\"Gender\", \"palette\":'ch:.25'}, fontsizes=4.5);"
      ],
      "metadata": {
        "id": "Sib5RtiiMYZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drug_data = drugdata[drugs_columns]"
      ],
      "metadata": {
        "id": "9ZvpkThdNB1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(\"count\", drug_data, fig_title=\"Count / Frequency for drug consumption\\n\\n\", rotate_label=False)"
      ],
      "metadata": {
        "id": "pA4DtIm3MoZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization for PCA analysis\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scale = StandardScaler()\n",
        "\n",
        "# Fitting only on training and test data\n",
        "drugnorm = scale.fit_transform(drugdata)"
      ],
      "metadata": {
        "id": "EW6gRt6Bi3Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drugnorm"
      ],
      "metadata": {
        "id": "3ccWIrD_nxKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PRINCIPAL COMPONENT ANALYSIS\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Perform PCA\n",
        "pca = PCA(n_components=30)\n",
        "pca.fit(drugnorm)\n",
        "\n",
        "# Plot explained variance\n",
        "plt.bar(range(pca.n_components_), pca.explained_variance_)\n",
        "plt.xlabel('Principle Component')\n",
        "plt.ylabel('Variance')\n",
        "plt.xlim([-0.5, 11])\n",
        "plt.ylim([0, 10])\n",
        "plt.savefig('pca1.png')\n",
        "plt.show()\n",
        "\n",
        "# Plot cumulative explained variance\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlim(0, 11, emit=True)\n",
        "plt.xlabel('Number of Principal Components')\n",
        "plt.ylabel('Cumulative Explained Variance')\n",
        "plt.savefig('pca2.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yRjpfv-MjZBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drugnorm = pd.DataFrame(drugnorm)"
      ],
      "metadata": {
        "id": "XSecdByxmPFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "#Preparing for test and Train Data\n",
        "Xs = drugnorm.iloc[:,:-1]\n",
        "ys = drugnorm.iloc[:,-1]"
      ],
      "metadata": {
        "id": "B9XTp6dpkZv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Importance Analysis with Ridge Regression\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.linear_model import RidgeCV # RidgeCV = GridSearchCV + Ridge (for regression)\n",
        "\n",
        "\n",
        "ridge = RidgeCV(alphas=np.logspace(-6, 6, num=5)).fit(Xs, ys)\n",
        "print(\"Ridge Regression Error: %.5f\" % (ridge.score(Xs, ys)))\n",
        "\n",
        "importance = np.abs(ridge.coef_)\n",
        "feature_names = np.array(Xs.columns)\n",
        "plt.figure(figsize = (15,10))\n",
        "plt.bar(height=importance, x=feature_names)\n",
        "plt.title(\"Feature importances via coefficients\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-NcJyC0nyQCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation Analysis and Heatmap Visualization"
      ],
      "metadata": {
        "id": "g-mxt3F5z784"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_matrix = drugdata.corr()\n",
        "\n",
        "# Create heatmap\n",
        "plt.figure(figsize = (20,20))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
        "\n",
        "# Set plot title\n",
        "plt.title('Correlation Heatmap')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "print(drugdata.corr().abs().nlargest(30,'VSA').index)\n",
        "print(drugdata.corr().abs().nlargest(30,'VSA').values[:,29])"
      ],
      "metadata": {
        "id": "eF5LC4d3nDQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#selecting the top 5"
      ],
      "metadata": {
        "id": "0rKsmOaoqDv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drugdata"
      ],
      "metadata": {
        "id": "J_Dvr9FHr-R8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drugg=drugdata.copy()"
      ],
      "metadata": {
        "id": "gLy1s2UFudC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data=drugg.drop(columns=[ 'Alcohol consumption','Extraversion','Caffeine consumption','Chocolate consumption','Ethnicity','Agreeableness','Education','Neuroticism','Gender','Openness to experience','Amphetamines consumption','Country', 'Methadone consumption', 'Heroin consumption', 'Nicotine consumption', 'Sensation seeking', 'Crack consumption', 'Ecstasy consumption','Magic mushrooms consumption', 'Age', 'Ketamine consumption', 'Impulsiveness', 'Conscientiousness', 'Amyl nitrite consumption', 'Openness to experience','Gender', 'Neuroticism', 'Education', 'Agreeableness', 'Ethnicity', 'Caffeine consumption','Ecstasy consumption', 'Alcohol consumption'],axis=1)"
      ],
      "metadata": {
        "id": "Y9jYVEhzktgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_matrix = new_data.corr()\n",
        "\n",
        "# Create heatmap\n",
        "plt.figure(figsize = (7,7))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
        "\n",
        "# Set plot title\n",
        "plt.title('Correlation Heatmap')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "print(drugdata.corr().abs().nlargest(6,'VSA').index)\n",
        "print(drugdata.corr().abs().nlargest(6,'VSA').values[:,5])"
      ],
      "metadata": {
        "id": "X9dTYzXRhWQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reclassifying the feature into 0 and 1, including the target variable"
      ],
      "metadata": {
        "id": "sdqH6xQ0hqgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_data.replace({2:1,3:1,4:1,5:1,6:1, 7: 1}, inplace=True)"
      ],
      "metadata": {
        "id": "CpL5_sea_roZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data.head()"
      ],
      "metadata": {
        "id": "eJLWbKEPArh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preparation for Machine Learning Models"
      ],
      "metadata": {
        "id": "G-3oTsxJ0Ham"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Preparing for test and Train Data\n",
        "X = new_data.iloc[:,:-1]\n",
        "y = new_data.iloc[:,-1]"
      ],
      "metadata": {
        "id": "eSk5fFTHutEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "BY4lsMKZwaOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine Learning Model Training and Evaluation"
      ],
      "metadata": {
        "id": "5Qc7MXkl0PfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data splitting for training and testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "c2Vy_JkexjJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization for processing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scale = StandardScaler()\n",
        "\n",
        "# Fitting only on training and test data\n",
        "X_train = scale.fit_transform(X_train)\n",
        "X_test = scale.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "J-6a-kBlyp1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.gaussian_process.kernels import RBF"
      ],
      "metadata": {
        "id": "4y-Fn2Sd3UaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "kernel = 1.0 * RBF(1.0)\n",
        "gp_clf =  GaussianProcessClassifier(kernel=kernel)\n",
        "gp_clf.fit(X_train, y_train)\n",
        "print(\"GaussianProcessClassifier accuracy: %.2f%%\" % (100*gp_clf.score(X_test, y_test)))"
      ],
      "metadata": {
        "id": "ql9Gl_VK80yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot posteriors\n",
        "plt.figure(figsize = (10,5))\n",
        "plt.plot(\n",
        "    y_test,\n",
        "    gp_clf.predict_proba(X_test[:len(X_test)])[:, 1],\n",
        "    \"r\",\n",
        "    label=\"kernel: %s\" % RBF,\n",
        "    )\n",
        "\n",
        "plt.xlabel(\"Feature\")\n",
        "plt.ylabel(\"Class 1 probability\")\n",
        "plt.xlim(-0.1, 1.1)\n",
        "plt.ylim(-0.1, 1.1)\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QJfZ75OuIARZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gaussian Process Classifier Visualization and Analysis**"
      ],
      "metadata": {
        "id": "IyDgMjuf0ZdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from matplotlib import cm\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import ConstantKernel as C\n",
        "from sklearn.gaussian_process.kernels import DotProduct\n",
        "\n",
        "# A few constants\n",
        "lim = 8\n",
        "\n",
        "def g(x):\n",
        "    \"\"\"The function to predict (classification will then consist in predicting\n",
        "    whether g(x) <= 0 or not)\"\"\"\n",
        "    return 5.0 - x[:, 1] - 0.5 * x[:, 0] ** 2.0\n",
        "\n",
        "# Generate some example data\n",
        "np.random.seed(42)\n",
        "X = np.random.uniform(low=-lim, high=lim, size=(100, 2))\n",
        "y = (g(X) <= 0).astype(int)\n",
        "\n",
        "# Instantiate and fit Gaussian Process Model\n",
        "kernel = C(0.1, (1e-5, np.inf)) * DotProduct(sigma_0=0.1) ** 2\n",
        "gp = GaussianProcessClassifier(kernel=kernel)\n",
        "gp.fit(X, y)\n",
        "print(\"Learned kernel: %s \" % gp.kernel_)\n",
        "\n",
        "# Evaluate real function and the predicted probability\n",
        "res = 50\n",
        "x1, x2 = np.meshgrid(np.linspace(-lim, lim, res), np.linspace(-lim, lim, res))\n",
        "xx = np.vstack([x1.reshape(x1.size), x2.reshape(x2.size)]).T\n",
        "\n",
        "y_true = g(xx)\n",
        "y_prob = gp.predict_proba(xx)[:, 1]\n",
        "y_true = y_true.reshape((res, res))\n",
        "y_prob = y_prob.reshape((res, res))\n",
        "\n",
        "# Plot the probabilistic classification iso-values\n",
        "fig, ax = plt.subplots()\n",
        "ax.axes.set_aspect(\"equal\")\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "ax.set_xticklabels([])\n",
        "ax.set_yticklabels([])\n",
        "plt.xlabel(\"$x_1$\")\n",
        "plt.ylabel(\"$x_2$\")\n",
        "\n",
        "cax = plt.imshow(y_prob, cmap=cm.gray_r, alpha=0.8, extent=(-lim, lim, -lim, lim))\n",
        "norm = plt.matplotlib.colors.Normalize(vmin=0.0, vmax=0.9)\n",
        "cb = plt.colorbar(cax, ticks=[0.0, 0.2, 0.4, 0.6, 0.8, 1.0], norm=norm)\n",
        "cb.set_label(r\"${\\rm \\mathbb{P}}\\left[\\widehat{G}(\\mathbf{x}) \\leq 0\\right]$\")\n",
        "plt.clim(0, 1)\n",
        "\n",
        "plt.plot(X[y <= 0, 0], X[y <= 0, 1], \"r.\", markersize=12)\n",
        "plt.plot(X[y > 0, 0], X[y > 0, 1], \"b.\", markersize=12)\n",
        "\n",
        "plt.contour(x1, x2, y_true, [0.0], colors=\"k\", linestyles=\"dashdot\")\n",
        "\n",
        "cs = plt.contour(x1, x2, y_prob, [0.666], colors=\"b\", linestyles=\"solid\")\n",
        "plt.clabel(cs, fontsize=11)\n",
        "\n",
        "cs = plt.contour(x1, x2, y_prob, [0.5], colors=\"k\", linestyles=\"dashed\")\n",
        "plt.clabel(cs, fontsize=11)\n",
        "\n",
        "cs = plt.contour(x1, x2, y_prob, [0.334], colors=\"r\", linestyles=\"solid\")\n",
        "plt.clabel(cs, fontsize=11)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uLaJds0FcFw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree, Logistic Regression, and SVM Models**"
      ],
      "metadata": {
        "id": "KkmoOF6O0hzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#run again with entropy to check for better result using the best given parameters above\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt_clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=5, min_samples_leaf=2, min_impurity_decrease=0.1)\n",
        "dt_clf.fit(X_train, y_train)\n",
        "print(\"Decision Tree accuracy: %.2f%%\" % (100*dt_clf.score(X_test, y_test)))"
      ],
      "metadata": {
        "id": "Bf3SHiFXzIkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lg_clf = LogisticRegression(penalty='l2', C=1.0)\n",
        "lg_clf.fit(X_train, y_train)\n",
        "print(\"Logistic Regression accuracy: %.2f%%\" % (100*lg_clf.score(X_test, y_test)))"
      ],
      "metadata": {
        "id": "4-1Bl5780Fi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using svm.SVC this time around\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "# Create an SVM classifier\n",
        "clf = svm.SVC()\n",
        "\n",
        "# Train the classifier on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Use the trained classifier to make predictions on the test data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"SVM Accuracy: %.2f%%\" % (100*accuracy))"
      ],
      "metadata": {
        "id": "HmUVq8lz0enj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes Model Implementation and Evaluation**"
      ],
      "metadata": {
        "id": "9lxI0gWh0yt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb_clf = GaussianNB()\n",
        "gnb_clf = gnb_clf.fit(X_train, y_train)\n",
        "gnb_clf = gnb_clf.score(X_test,y_test)\n",
        "print(\"GNB Accuracy: %.2f%%\" % (100*gnb_clf))"
      ],
      "metadata": {
        "id": "nXVhOwee0ukd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execution Time Calculation\n",
        "sp = time.time()\n",
        "time_taken = (sp-st)/60\n",
        "print(\"time_taken is: %0.1f Minutes\" % (time_taken))"
      ],
      "metadata": {
        "id": "e1g-6qx909dR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}